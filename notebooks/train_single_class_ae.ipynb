{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will help you train a vanilla Point-Cloud AE with the basic architecture we used in our paper.\n",
    "    (it assumes latent_3d_points is in the PYTHONPATH and the structural losses have been compiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/gy46/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/gy46/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from latent_3d_points.src.ae_templates import mlp_architecture_ala_iclr_18, default_train_params\n",
    "from latent_3d_points.src.autoencoder import Configuration as Conf\n",
    "from latent_3d_points.src.point_net_ae import PointNetAutoEncoder\n",
    "\n",
    "from latent_3d_points.src.in_out import snc_category_to_synth_id, create_dir, PointCloudDataSet, \\\n",
    "                                        load_all_point_clouds_under_folder\n",
    "\n",
    "from latent_3d_points.src.tf_utils import reset_tf_graph\n",
    "from latent_3d_points.src.general_utils import plot_3d_point_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Basic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapenetcorev2_emd_ae_chair\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args()\n",
    "top_out_dir = '../data/'                      # Use to save Neural-Net check-points etc.\n",
    "top_in_dir = '../data/ShapeNetCore.v2.PC15k/' # Top-dir of where point-clouds are stored.\n",
    "\n",
    "# experiment_name = 'single_class_ae_emd'\n",
    "n_pc_points = 2048                # Number of points per model.\n",
    "bneck_size = 128                  # Bottleneck-AE size\n",
    "# ae_loss = 'chamfer'                   # Loss to optimize: 'emd' or 'chamfer'\n",
    "ae_loss = 'emd'                   # Loss to optimize: 'emd' or 'chamfer'\n",
    "# class_name = raw_input('Give me the class name (e.g. \"chair\"): ').lower()\n",
    "# class_name = 'airplane'\n",
    "class_name = 'chair'\n",
    "experiment_name = 'shapenetcorev2_%s_ae_%s'%(ae_loss, class_name)\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Point-Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03001627\n",
      "../data/ShapeNetCore.v2.PC15k/03001627/train\n"
     ]
    }
   ],
   "source": [
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "class_dir = osp.join(top_in_dir , syn_id, 'train')\n",
    "print(syn_id)\n",
    "print(class_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4612 pclouds were loaded. They belong in 1 shape-classes.\n"
     ]
    }
   ],
   "source": [
    "all_pc_data = load_all_point_clouds_under_folder(\n",
    "    class_dir, n_threads=8, file_ending='.npy', max_num_points=2048, verbose=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load default training parameters (some of which are listed beloq). For more details please print the configuration object.\n",
    "\n",
    "    'batch_size': 50   \n",
    "    \n",
    "    'denoising': False     (# by default AE is not denoising)\n",
    "\n",
    "    'learning_rate': 0.0005\n",
    "\n",
    "    'z_rotate': False      (# randomly rotate models of each batch)\n",
    "    \n",
    "    'loss_display_step': 1 (# display loss at end of these many epochs)\n",
    "    'saver_step': 10       (# over how many epochs to save neural-network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = default_train_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, enc_args, dec_args = mlp_architecture_ala_iclr_18(n_pc_points, bneck_size)\n",
    "train_dir = create_dir(osp.join(top_out_dir, experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Conf(n_input = [n_pc_points, 3],\n",
    "            loss = ae_loss,\n",
    "            training_epochs = train_params['training_epochs'],\n",
    "            batch_size = train_params['batch_size'],\n",
    "            denoising = train_params['denoising'],\n",
    "            learning_rate = train_params['learning_rate'],\n",
    "            train_dir = train_dir,\n",
    "            loss_display_step = train_params['loss_display_step'],\n",
    "            saver_step = train_params['saver_step'],\n",
    "            z_rotate = train_params['z_rotate'],\n",
    "            encoder = encoder,\n",
    "            decoder = decoder,\n",
    "            encoder_args = enc_args,args = parser.parse_args()\n",
    "\n",
    "            decoder_args = dec_args\n",
    "           )\n",
    "conf.experiment_name = experiment_name\n",
    "conf.held_out_step = 5   # How often to evaluate/print out loss on \n",
    "                         # held_out data (if they are provided in ae.train() ).\n",
    "conf.save(osp.join(train_dir, 'configuration'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the above lines, you can reload a saved model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pre_trained_ae = False\n",
    "restore_epoch = 1000\n",
    "if load_pre_trained_ae:\n",
    "    conf = Conf.load(train_dir + '/configuration')\n",
    "    reset_tf_graph()\n",
    "    ae = PointNetAutoEncoder(conf.experiment_name, conf)\n",
    "    ae.restore_model(conf.train_dir, epoch=restore_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build AE Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Encoder\n",
      "('encoder_conv_layer_0', 'conv params = ', 256)\n",
      "('bnorm params = ', 128)\n",
      "Tensor(\"shapenetcorev2_emd_ae_chair_2/Relu:0\", shape=(?, 2048, 64), dtype=float32)\n",
      "('output size:', 131072, '\\n')\n",
      "('encoder_conv_layer_1', 'conv params = ', 8320)\n",
      "('bnorm params = ', 256)\n",
      "Tensor(\"shapenetcorev2_emd_ae_chair_2/Relu_1:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "('output size:', 262144, '\\n')\n",
      "('encoder_conv_layer_2', 'conv params = ', 16512)\n",
      "('bnorm params = ', 256)\n",
      "Tensor(\"shapenetcorev2_emd_ae_chair_2/Relu_2:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "('output size:', 262144, '\\n')\n",
      "('encoder_conv_layer_3', 'conv params = ', 33024)\n",
      "('bnorm params = ', 512)\n",
      "Tensor(\"shapenetcorev2_emd_ae_chair_2/Relu_3:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "('output size:', 524288, '\\n')\n",
      "('encoder_conv_layer_4', 'conv params = ', 32896)\n",
      "('bnorm params = ', 256)\n",
      "Tensor(\"shapenetcorev2_emd_ae_chair_2/Relu_4:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "('output size:', 262144, '\\n')\n",
      "Tensor(\"shapenetcorev2_emd_ae_chair_2/Max:0\", shape=(?, 128), dtype=float32)\n",
      "Building Decoder\n",
      "('decoder_fc_0', 'FC params = ', 33024)\n",
      "Tensor(\"shapenetcorev2_emd_ae_chair_2/Relu_5:0\", shape=(?, 256), dtype=float32)\n",
      "('output size:', 256, '\\n')\n",
      "('decoder_fc_1', 'FC params = ', 65792)\n",
      "Tensor(\"shapenetcorev2_emd_ae_chair_2/Relu_6:0\", shape=(?, 256), dtype=float32)\n",
      "('output size:', 256, '\\n')\n",
      "('decoder_fc_2', 'FC params = ', 1579008)\n",
      "Tensor(\"shapenetcorev2_emd_ae_chair_2/decoder_fc_2/BiasAdd:0\", shape=(?, 6144), dtype=float32)\n",
      "('output size:', 6144, '\\n')\n"
     ]
    }
   ],
   "source": [
    "reset_tf_graph()\n",
    "ae = PointNetAutoEncoder(conf.experiment_name, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the AE (save output to train_stats.txt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '0001', 'training time (minutes)=', '0.2674', 'loss=', '0.484379471')\n",
      "INFO:tensorflow:../data/shapenetcorev2_emd_ae_chair/models.ckpt-1 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0002', 'training time (minutes)=', '0.2601', 'loss=', '0.372380334')\n",
      "('Epoch:', '0003', 'training time (minutes)=', '0.2686', 'loss=', '0.348191769')\n",
      "('Epoch:', '0004', 'training time (minutes)=', '0.2669', 'loss=', '0.333794559')\n",
      "('Epoch:', '0005', 'training time (minutes)=', '0.2661', 'loss=', '0.325950996')\n",
      "('Epoch:', '0006', 'training time (minutes)=', '0.2649', 'loss=', '0.319383446')\n",
      "('Epoch:', '0007', 'training time (minutes)=', '0.2629', 'loss=', '0.313504867')\n",
      "('Epoch:', '0008', 'training time (minutes)=', '0.2642', 'loss=', '0.310594104')\n",
      "('Epoch:', '0009', 'training time (minutes)=', '0.2633', 'loss=', '0.303052879')\n",
      "('Epoch:', '0010', 'training time (minutes)=', '0.2672', 'loss=', '0.300662286')\n",
      "INFO:tensorflow:../data/shapenetcorev2_emd_ae_chair/models.ckpt-10 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0011', 'training time (minutes)=', '0.2624', 'loss=', '0.298562050')\n",
      "('Epoch:', '0012', 'training time (minutes)=', '0.2630', 'loss=', '0.294624361')\n",
      "('Epoch:', '0013', 'training time (minutes)=', '0.2631', 'loss=', '0.293724353')\n",
      "('Epoch:', '0014', 'training time (minutes)=', '0.2633', 'loss=', '0.290867564')\n",
      "('Epoch:', '0015', 'training time (minutes)=', '0.2686', 'loss=', '0.289595654')\n",
      "('Epoch:', '0016', 'training time (minutes)=', '0.2620', 'loss=', '0.287914841')\n",
      "('Epoch:', '0017', 'training time (minutes)=', '0.2622', 'loss=', '0.286506146')\n",
      "('Epoch:', '0018', 'training time (minutes)=', '0.2628', 'loss=', '0.285617794')\n",
      "('Epoch:', '0019', 'training time (minutes)=', '0.2632', 'loss=', '0.283154593')\n",
      "('Epoch:', '0020', 'training time (minutes)=', '0.2628', 'loss=', '0.283026305')\n",
      "INFO:tensorflow:../data/shapenetcorev2_emd_ae_chair/models.ckpt-20 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0021', 'training time (minutes)=', '0.2661', 'loss=', '0.280932686')\n",
      "('Epoch:', '0022', 'training time (minutes)=', '0.2680', 'loss=', '0.280781148')\n",
      "('Epoch:', '0023', 'training time (minutes)=', '0.2654', 'loss=', '0.277634287')\n",
      "('Epoch:', '0024', 'training time (minutes)=', '0.2647', 'loss=', '0.274994754')\n",
      "('Epoch:', '0025', 'training time (minutes)=', '0.2659', 'loss=', '0.276006372')\n",
      "('Epoch:', '0026', 'training time (minutes)=', '0.2634', 'loss=', '0.276433943')\n",
      "('Epoch:', '0027', 'training time (minutes)=', '0.2661', 'loss=', '0.273884086')\n",
      "('Epoch:', '0028', 'training time (minutes)=', '0.2650', 'loss=', '0.271648906')\n",
      "('Epoch:', '0029', 'training time (minutes)=', '0.2621', 'loss=', '0.270481226')\n",
      "('Epoch:', '0030', 'training time (minutes)=', '0.2643', 'loss=', '0.272982004')\n",
      "INFO:tensorflow:../data/shapenetcorev2_emd_ae_chair/models.ckpt-30 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0031', 'training time (minutes)=', '0.2655', 'loss=', '0.269780130')\n",
      "('Epoch:', '0032', 'training time (minutes)=', '0.2617', 'loss=', '0.268552459')\n",
      "('Epoch:', '0033', 'training time (minutes)=', '0.2674', 'loss=', '0.267792752')\n",
      "('Epoch:', '0034', 'training time (minutes)=', '0.2621', 'loss=', '0.267131196')\n",
      "('Epoch:', '0035', 'training time (minutes)=', '0.2664', 'loss=', '0.266781314')\n",
      "('Epoch:', '0036', 'training time (minutes)=', '0.2645', 'loss=', '0.267138629')\n",
      "('Epoch:', '0037', 'training time (minutes)=', '0.2628', 'loss=', '0.266038216')\n",
      "('Epoch:', '0038', 'training time (minutes)=', '0.2630', 'loss=', '0.266327539')\n",
      "('Epoch:', '0039', 'training time (minutes)=', '0.2621', 'loss=', '0.265947538')\n",
      "('Epoch:', '0040', 'training time (minutes)=', '0.2632', 'loss=', '0.264393730')\n",
      "INFO:tensorflow:../data/shapenetcorev2_emd_ae_chair/models.ckpt-40 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0041', 'training time (minutes)=', '0.2653', 'loss=', '0.263363579')\n",
      "('Epoch:', '0042', 'training time (minutes)=', '0.2631', 'loss=', '0.265335130')\n",
      "('Epoch:', '0043', 'training time (minutes)=', '0.2615', 'loss=', '0.262617248')\n",
      "('Epoch:', '0044', 'training time (minutes)=', '0.2631', 'loss=', '0.261456693')\n",
      "('Epoch:', '0045', 'training time (minutes)=', '0.2634', 'loss=', '0.263354437')\n",
      "('Epoch:', '0046', 'training time (minutes)=', '0.2633', 'loss=', '0.262049372')\n",
      "('Epoch:', '0047', 'training time (minutes)=', '0.2625', 'loss=', '0.259622504')\n",
      "('Epoch:', '0048', 'training time (minutes)=', '0.2639', 'loss=', '0.259949348')\n",
      "('Epoch:', '0049', 'training time (minutes)=', '0.2626', 'loss=', '0.260859996')\n",
      "('Epoch:', '0050', 'training time (minutes)=', '0.2722', 'loss=', '0.259578894')\n",
      "INFO:tensorflow:../data/shapenetcorev2_emd_ae_chair/models.ckpt-50 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0051', 'training time (minutes)=', '0.2648', 'loss=', '0.258410549')\n",
      "('Epoch:', '0052', 'training time (minutes)=', '0.2660', 'loss=', '0.258095205')\n",
      "('Epoch:', '0053', 'training time (minutes)=', '0.2657', 'loss=', '0.260636208')\n",
      "('Epoch:', '0054', 'training time (minutes)=', '0.2625', 'loss=', '0.258961351')\n",
      "('Epoch:', '0055', 'training time (minutes)=', '0.2640', 'loss=', '0.257362796')\n",
      "('Epoch:', '0056', 'training time (minutes)=', '0.2646', 'loss=', '0.257102000')\n",
      "('Epoch:', '0057', 'training time (minutes)=', '0.2628', 'loss=', '0.255317431')\n",
      "('Epoch:', '0058', 'training time (minutes)=', '0.2645', 'loss=', '0.254110945')\n",
      "('Epoch:', '0059', 'training time (minutes)=', '0.2666', 'loss=', '0.256047149')\n",
      "('Epoch:', '0060', 'training time (minutes)=', '0.2660', 'loss=', '0.255289637')\n",
      "INFO:tensorflow:../data/shapenetcorev2_emd_ae_chair/models.ckpt-60 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0061', 'training time (minutes)=', '0.2634', 'loss=', '0.253431379')\n",
      "('Epoch:', '0062', 'training time (minutes)=', '0.2621', 'loss=', '0.255268295')\n",
      "('Epoch:', '0063', 'training time (minutes)=', '0.2634', 'loss=', '0.254167028')\n",
      "('Epoch:', '0064', 'training time (minutes)=', '0.2629', 'loss=', '0.254702113')\n",
      "('Epoch:', '0065', 'training time (minutes)=', '0.2628', 'loss=', '0.255265497')\n",
      "('Epoch:', '0066', 'training time (minutes)=', '0.2650', 'loss=', '0.252825058')\n",
      "('Epoch:', '0067', 'training time (minutes)=', '0.2638', 'loss=', '0.252237843')\n",
      "('Epoch:', '0068', 'training time (minutes)=', '0.2653', 'loss=', '0.253203181')\n",
      "('Epoch:', '0069', 'training time (minutes)=', '0.2631', 'loss=', '0.251038876')\n",
      "('Epoch:', '0070', 'training time (minutes)=', '0.2631', 'loss=', '0.251842597')\n",
      "INFO:tensorflow:../data/shapenetcorev2_emd_ae_chair/models.ckpt-70 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0071', 'training time (minutes)=', '0.2685', 'loss=', '0.252410285')\n",
      "('Epoch:', '0072', 'training time (minutes)=', '0.2632', 'loss=', '0.250338588')\n",
      "('Epoch:', '0073', 'training time (minutes)=', '0.2615', 'loss=', '0.253155839')\n",
      "('Epoch:', '0074', 'training time (minutes)=', '0.2626', 'loss=', '0.249473253')\n",
      "('Epoch:', '0075', 'training time (minutes)=', '0.2634', 'loss=', '0.250469235')\n",
      "('Epoch:', '0076', 'training time (minutes)=', '0.2624', 'loss=', '0.252625300')\n",
      "('Epoch:', '0077', 'training time (minutes)=', '0.2615', 'loss=', '0.249036338')\n",
      "('Epoch:', '0078', 'training time (minutes)=', '0.2653', 'loss=', '0.250475093')\n",
      "('Epoch:', '0079', 'training time (minutes)=', '0.2632', 'loss=', '0.250156738')\n",
      "('Epoch:', '0080', 'training time (minutes)=', '0.2629', 'loss=', '0.248608469')\n",
      "INFO:tensorflow:../data/shapenetcorev2_emd_ae_chair/models.ckpt-80 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0081', 'training time (minutes)=', '0.2635', 'loss=', '0.248747594')\n",
      "('Epoch:', '0082', 'training time (minutes)=', '0.2637', 'loss=', '0.248443366')\n",
      "('Epoch:', '0083', 'training time (minutes)=', '0.2635', 'loss=', '0.248119814')\n",
      "('Epoch:', '0084', 'training time (minutes)=', '0.2701', 'loss=', '0.246814551')\n",
      "('Epoch:', '0085', 'training time (minutes)=', '0.2630', 'loss=', '0.248449701')\n",
      "('Epoch:', '0086', 'training time (minutes)=', '0.2643', 'loss=', '0.246293343')\n",
      "('Epoch:', '0087', 'training time (minutes)=', '0.2628', 'loss=', '0.247949464')\n",
      "('Epoch:', '0088', 'training time (minutes)=', '0.2621', 'loss=', '0.246600382')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '0089', 'training time (minutes)=', '0.2623', 'loss=', '0.247901954')\n",
      "('Epoch:', '0090', 'training time (minutes)=', '0.2643', 'loss=', '0.245819586')\n",
      "INFO:tensorflow:../data/shapenetcorev2_emd_ae_chair/models.ckpt-90 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0091', 'training time (minutes)=', '0.2632', 'loss=', '0.245382444')\n",
      "('Epoch:', '0092', 'training time (minutes)=', '0.2654', 'loss=', '0.246452942')\n",
      "('Epoch:', '0093', 'training time (minutes)=', '0.2650', 'loss=', '0.245778974')\n",
      "('Epoch:', '0094', 'training time (minutes)=', '0.2639', 'loss=', '0.245508820')\n",
      "('Epoch:', '0095', 'training time (minutes)=', '0.2617', 'loss=', '0.243743368')\n",
      "('Epoch:', '0096', 'training time (minutes)=', '0.2673', 'loss=', '0.245229700')\n",
      "('Epoch:', '0097', 'training time (minutes)=', '0.2634', 'loss=', '0.244245832')\n",
      "('Epoch:', '0098', 'training time (minutes)=', '0.2629', 'loss=', '0.245878958')\n",
      "('Epoch:', '0099', 'training time (minutes)=', '0.2640', 'loss=', '0.243649054')\n",
      "('Epoch:', '0100', 'training time (minutes)=', '0.2621', 'loss=', '0.243920494')\n",
      "INFO:tensorflow:../data/shapenetcorev2_emd_ae_chair/models.ckpt-100 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "('Epoch:', '0101', 'training time (minutes)=', '0.2626', 'loss=', '0.244436788')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9a18bf8bb796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbuf_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# Make 'training_stats' file to flush each output line regarding training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_stats.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_pc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gy46/latent_3d_points/src/autoencoder.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, configuration, log_file, held_out_data)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gy46/latent_3d_points/src/point_net_ae.pyc\u001b[0m in \u001b[0;36m_single_epoch_train\u001b[0;34m(self, train_data, configuration, only_fw)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;31m# Compute average loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gy46/latent_3d_points/src/autoencoder.pyc\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, GT)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_reconstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_reconstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mis_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gy46/anaconda3/envs/tfpy2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gy46/anaconda3/envs/tfpy2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gy46/anaconda3/envs/tfpy2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gy46/anaconda3/envs/tfpy2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gy46/anaconda3/envs/tfpy2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "buf_size = 1 # Make 'training_stats' file to flush each output line regarding training.\n",
    "fout = open(osp.join(conf.train_dir, 'train_stats.txt'), 'a', buf_size)\n",
    "train_stats = ae.train(all_pc_data, conf, log_file=fout)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a batch of reconstuctions and their latent-codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "class_dir = osp.join(top_in_dir , syn_id, 'val')\n",
    "print(syn_id)\n",
    "print(class_dir)\n",
    "all_pc_data = load_all_point_clouds_under_folder(\n",
    "    class_dir, n_threads=8, file_ending='.npy', max_num_points=2048, verbose=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_pc, feed_model_names, _ = all_pc_data.next_batch(10)\n",
    "reconstructions = ae.reconstruct(feed_pc)[0]\n",
    "latent_codes = ae.transform(feed_pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use any plotting mechanism such as matplotlib to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_point_cloud(xs, ys, zs, s=1):\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(xs, ys, zs, s=s)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# i = random.choice(range(reconstructions.shape[0]))\n",
    "for i in range(reconstructions.shape[0]):\n",
    "    print(\"Recon\")\n",
    "    plot_point_cloud(reconstructions[i][:, 0], reconstructions[i][:, 2], \n",
    "                     reconstructions[i][:, 1]);\n",
    "    print(\"Gtrs\")\n",
    "    plot_point_cloud(feed_pc[i][:, 0], feed_pc[i][:, 2], feed_pc[i][:, 1]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Deprecated) Generate the latent codes for train/test/val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Loader that takes a list of file names\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm as tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from latent_3d_points.src.in_out import snc_synth_id_to_category\n",
    "cate_to_synsetid = {v:k for k,v in snc_synth_id_to_category.items()}\n",
    "\n",
    "class Uniform15KPC(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, subdirs, sample_size=2048, split='train'):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.sample_size = sample_size\n",
    "        self.subdirs = subdirs\n",
    "\n",
    "        self.stats = []\n",
    "        self.train_points = []\n",
    "        self.test_points  = []\n",
    "        for subd in tqdm(self.subdirs, desc='Subdirectories', leave=True):\n",
    "            sub_path = os.path.join(root_dir, subd, self.split)\n",
    "            for x in tqdm(os.listdir(sub_path), desc='shapes', leave=False):\n",
    "                if not x.endswith('.npy'):\n",
    "                    continue\n",
    "\n",
    "                obj_fname = os.path.join(sub_path, x)\n",
    "                try:\n",
    "                    point_cloud = np.load(obj_fname) # (15k, 3)\n",
    "                except Exception as e:\n",
    "                    print(\"Exception encountered loading :%s\"%obj_fname)\n",
    "                    print(e)\n",
    "                    continue\n",
    "                assert point_cloud.shape[0] == 15000\n",
    "                tr_pc = point_cloud[:10000, [0,2,1]]\n",
    "                te_pc = point_cloud[10000:, [0,2,1]]\n",
    "                m = point_cloud.reshape(15000,3).mean(axis=0).reshape(1,1,3)\n",
    "                s = point_cloud.reshape(15000*3).std().reshape(1,1,1)\n",
    "                self.stats.append((m, s))\n",
    "                \n",
    "                self.train_points.append((tr_pc[np.newaxis,...] - m)/s)\n",
    "                self.test_points.append((te_pc[np.newaxis,...] - m)/s)\n",
    "                \n",
    "\n",
    "        self.tr_sample_size = min(10000, sample_size)\n",
    "        self.te_sample_size = min(5000, sample_size)\n",
    "        print(\"Total number of data:%d\"%len(self.train_points))\n",
    "        print(\"Min number of points: (train)%d (test)%d\"\\\n",
    "              %(self.tr_sample_size, self.te_sample_size))\n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_points)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tr_out = self.train_points[idx]\n",
    "        tr_idxs = np.random.choice(tr_out.shape[1], self.tr_sample_size)\n",
    "        tr_out = tr_out[0,tr_idxs,:]\n",
    "\n",
    "        te_out = self.test_points[idx]\n",
    "        te_idxs = np.random.choice(te_out.shape[1], self.te_sample_size)\n",
    "        te_out = te_out[0,te_idxs,:]\n",
    "\n",
    "        return tr_out, te_out\n",
    "\n",
    "    \n",
    "\n",
    "class ShapeNet15kPointClouds(Uniform15KPC):\n",
    "\n",
    "    def __init__(self, root_dir=\"../data/ShapeNetV1PCOutput\",\n",
    "                 categories=['airplane'], sample_size=2048, split='train'):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        assert self.split in ['train', 'test', 'val']\n",
    "        self.sample_size = sample_size\n",
    "        self.cates = categories\n",
    "        self.synset_ids = [cate_to_synsetid[c] for c in self.cates]\n",
    "        super(ShapeNet15kPointClouds, self).__init__(root_dir, self.synset_ids, sample_size=sample_size, split=split)\n",
    "\n",
    "batch_size=128\n",
    "tr_ds = ShapeNet15kPointClouds(categories=[class_name], split='train')\n",
    "tr_loader = DataLoader(dataset=tr_ds, batch_size=batch_size,\n",
    "                       shuffle=False, num_workers=4, drop_last=False)\n",
    "print(len(tr_loader))\n",
    "val_ds = ShapeNet15kPointClouds(categories=[class_name], split='val')\n",
    "val_loader = DataLoader(dataset=val_ds, batch_size=batch_size,\n",
    "                        shuffle=False, num_workers=4, drop_last=False)\n",
    "print(len(val_loader))\n",
    "te_ds = ShapeNet15kPointClouds(categories=[class_name], split='test')\n",
    "te_loader = DataLoader(dataset=te_ds, batch_size=batch_size,\n",
    "                       shuffle=False, num_workers=4, drop_last=False)\n",
    "print(len(te_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(loader, split):\n",
    "    all_tr_latents = []\n",
    "    all_te_latents = []\n",
    "    all_tr = []\n",
    "    all_te = []\n",
    "    for tr_pc, te_pc in tqdm(loader):\n",
    "        tr_pc_latent = ae.transform(tr_pc)\n",
    "        te_pc_latent = ae.transform(te_pc)\n",
    "        all_tr_latents.append(tr_pc_latent)\n",
    "        all_te_latents.append(te_pc_latent)\n",
    "        all_tr.append(tr_pc)\n",
    "        all_te.append(te_pc)\n",
    "\n",
    "    print(len(all_tr_latents), len(all_te_latents))\n",
    "    all_tr_latents = np.concatenate(all_tr_latents)\n",
    "    all_te_latents = np.concatenate(all_te_latents)\n",
    "    all_tr = np.concatenate(all_tr)\n",
    "    all_te = np.concatenate(all_te)\n",
    "    print(all_tr_latents.shape)\n",
    "    print(all_te_latents.shape)\n",
    "    tr_latent_save_dir = \"../data/ShapeNetV1PCOutput_latent/%s/%s_%s_latent_tr.npy\"\\\n",
    "                         %(cate_to_synsetid[class_name], split, ae_loss)\n",
    "    te_latent_save_dir = \"../data/ShapeNetV1PCOutput_latent/%s/%s_%s_latent_te.npy\"\\\n",
    "                         %(cate_to_synsetid[class_name], split, ae_loss)\n",
    "    tr_pc_save_dir = \"../data/ShapeNetV1PCOutput_latent/%s/%s_%s_pc_tr.npy\"\\\n",
    "                     %(cate_to_synsetid[class_name], split, ae_loss)\n",
    "    te_pc_save_dir = \"../data/ShapeNetV1PCOutput_latent/%s/%s_%s_pc_te.npy\"\\\n",
    "                     %(cate_to_synsetid[class_name], split, ae_loss)\n",
    "    print(tr_latent_save_dir)\n",
    "    print(te_latent_save_dir)\n",
    "    print(tr_pc_save_dir)\n",
    "    print(te_pc_save_dir)\n",
    "    np.save(tr_latent_save_dir, all_tr_latents)\n",
    "    np.save(te_latent_save_dir, all_te_latents)\n",
    "    np.save(tr_pc_save_dir, all_tr)\n",
    "    np.save(te_pc_save_dir, all_te)\n",
    "    \n",
    "# save(tr_loader, 'train')\n",
    "# save(val_loader, 'val')\n",
    "# save(te_loader, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "class_dir = osp.join(top_in_dir , syn_id, 'val')\n",
    "print(syn_id)\n",
    "print(class_dir)\n",
    "all_pc_data = load_all_point_clouds_under_folder(\n",
    "    class_dir, n_threads=8, file_ending='.npy', max_num_points=2048, verbose=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_pc, _, _ = all_pc_data.full_epoch_data()\n",
    "feed_pc_tr_all = feed_pc[:, :n_pc_points]\n",
    "feed_pc_te_all = feed_pc[:, -n_pc_points:]\n",
    "print(feed_pc_tr_all.shape)\n",
    "print(feed_pc_te_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sample = []\n",
    "all_ref = []\n",
    "for i in range(feed_pc_tr_all.shape[0]):\n",
    "    feed_pc_tr = feed_pc_tr_all[i:i+1]\n",
    "    feed_pc_te = feed_pc_te_all[i:i+1]\n",
    "    reconstructions = ae.reconstruct(feed_pc_tr)[0]\n",
    "    all_sample.append(reconstructions)\n",
    "    all_ref.append(feed_pc_te)\n",
    "\n",
    "all_sample = np.concatenate(all_sample)\n",
    "all_ref = np.concatenate(all_ref)\n",
    "all_sample.shape, all_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latent_3d_points.src.evaluation_metrics_fast import MMD_COV_EMD_CD\n",
    "mmd_emd, mmd_cd, cov_emd, cov_cd = MMD_COV_EMD_CD(all_sample, all_ref, 100, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experiment_name)\n",
    "print(\"MMD-EMD:%s\"%mmd_emd)\n",
    "print(\"MMD-CD:%s\"%mmd_cd)\n",
    "# print(\"COV-EMD:%s\"%cov_emd)\n",
    "# print(\"COV-CD:%s\"%cov_cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy2.7",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
